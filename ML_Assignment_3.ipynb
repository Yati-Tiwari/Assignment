{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "209c269b",
   "metadata": {},
   "source": [
    "# **Machine Learning Assignment â€“ 3 (Linear & Logistic Regression)**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5f609d",
   "metadata": {},
   "source": [
    "## **Part I: Linear Regression**\n",
    "### **Task 1: Simple Linear Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba73fa0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load California Housing dataset\n",
    "data = fetch_california_housing()\n",
    "X = data.data[:, [3]]  # Using 'AveRooms' as a single feature\n",
    "y = data.target\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create and train model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Plot regression line\n",
    "plt.scatter(X_test, y_test, color=\"blue\", label=\"Actual Data\")\n",
    "plt.plot(X_test, y_pred, color=\"red\", linewidth=2, label=\"Regression Line\")\n",
    "plt.xlabel(\"Average Rooms\")\n",
    "plt.ylabel(\"House Price\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4103d01",
   "metadata": {},
   "source": [
    "### **Task 2: Multiple Linear Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27baf30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import math\n",
    "\n",
    "# Use first 4 features\n",
    "X = data.data[:, :4]\n",
    "y = data.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Metrics\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = math.sqrt(mse)\n",
    "\n",
    "print(f\"R-squared: {r2:.4f}\")\n",
    "print(f\"MSE: {mse:.4f}\")\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print('Coefficients:', model.coef_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7c7a66",
   "metadata": {},
   "source": [
    "### **Task 3: Feature Scaling and Normalization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f797a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Without scaling\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "print(\"R2 without scaling:\", r2_score(y_test, model.predict(X_test)))\n",
    "\n",
    "# With scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "model_scaled = LinearRegression()\n",
    "model_scaled.fit(X_train_scaled, y_train)\n",
    "print(\"R2 with scaling:\", r2_score(y_test, model_scaled.predict(X_test_scaled)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513a879b",
   "metadata": {},
   "source": [
    "### **Task 4: Model Interpretation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec24b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "df['Price'] = data.target\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.heatmap(df.corr(), annot=True, cmap=\"coolwarm\")\n",
    "plt.title(\"Correlation Matrix Heatmap\")\n",
    "plt.show()\n",
    "\n",
    "# Features with strongest relationship\n",
    "print(df.corr()['Price'].sort_values(ascending=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dfb26f2",
   "metadata": {},
   "source": [
    "## **Part II: Logistic Regression**\n",
    "### **Task 5: Binary Classification**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592b755d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "X = cancer.data\n",
    "y = cancer.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "log_model = LogisticRegression(max_iter=5000)\n",
    "log_model.fit(X_train, y_train)\n",
    "y_pred = log_model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# ROC curve\n",
    "y_prob = log_model.predict_proba(X_test)[:,1]\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
    "\n",
    "plt.plot(fpr, tpr, label=f\"AUC = {roc_auc_score(y_test, y_prob):.2f}\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f490fe",
   "metadata": {},
   "source": [
    "### **Task 6: Threshold Tuning and Probability Interpretation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79615710",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "thresholds = [0.3, 0.5, 0.7]\n",
    "for t in thresholds:\n",
    "    y_pred_thr = (y_prob >= t).astype(int)\n",
    "    print(f\"\\nThreshold: {t}\")\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_thr))\n",
    "    print(\"F1-score:\", classification_report(y_test, y_pred_thr, output_dict=True)['weighted avg']['f1-score'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ae596d",
   "metadata": {},
   "source": [
    "### **Task 7: Multiclass Classification (Optional)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91f9d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "log_model = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=1000)\n",
    "log_model.fit(X, y)\n",
    "y_pred = log_model.predict(X)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b9da84",
   "metadata": {},
   "source": [
    "\n",
    "## **Part III: General Questions**\n",
    "1. **What are the assumptions of linear regression?**  \n",
    "   - Linear relationship between features and target.  \n",
    "   - Errors are normally distributed with constant variance.  \n",
    "   - Independence of observations.  \n",
    "   - No multicollinearity among features.\n",
    "\n",
    "2. **When should you use logistic regression instead of linear regression?**  \n",
    "   - When target variable is categorical (e.g., 0/1). Logistic regression predicts probabilities, not continuous values.\n",
    "\n",
    "3. **What is the interpretation of coefficients in logistic regression?**  \n",
    "   - Each coefficient represents change in log-odds of the outcome for one unit increase in the feature.\n",
    "\n",
    "4. **What is the difference between sigmoid and softmax functions?**  \n",
    "   - Sigmoid is for binary classification (0-1 probability), while softmax generalizes it for multi-class probabilities summing to 1.\n",
    "\n",
    "5. **Why is R-squared not suitable for evaluating logistic regression models?**  \n",
    "   - R-squared is for continuous target models. For classification, metrics like AUC, accuracy, precision, and recall are used.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
